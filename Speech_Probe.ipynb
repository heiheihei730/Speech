{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probe研究\n",
    "\n",
    "主要研究SSL模型对于不同层级的表征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "# 其他常用库\n",
    "import glob\n",
    "import os\n",
    "import textgrids\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Transformer库\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from transformers import WhisperFeatureExtractor, WhisperModel\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "# Datasets库\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "from jiwer import wer\n",
    "\n",
    "import cca_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从本地加载huggingface上保存下来的数据集\n",
    "ds = load_from_disk(\"/data/chenhonghua/datasets/librispeech_test\")\n",
    "ds = ds['test.clean'] # 选择librispeech中的test clean数据集 \n",
    "# ds = load_from_disk(\"/data/chenhonghua/datasets/librispeech_asr_dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\").to(\"cuda\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer-wise analysis代码\n",
    "1. 让librispeech和对齐的文本进行匹配: *read_librispeech_alignments.py*\n",
    "2. 采集数据样本: *create_data_samples.py*，可以采集多个数据样本\n",
    "3. 提取模型的表征：*extract_rep.py*，得到表征的级别用span表示，模式用rep_type表示。\n",
    "4. 与上下文不相关的word embedding，从*prepare_wordsim_data.py*中获取数据，用*extract_static_word_embed.py*获取\n",
    "5. 评估layer-wise特征：*save_embeddings.py*下载数据，*get_scores.py*进行CCA、MI和WordSim打分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_librispeech_alignments\n",
    "#from utils import save_dct, write_to_file, load_dct, read_lst\n",
    "\n",
    "class LibrispeechAlign:\n",
    "    def save_data(self, data_dir, dataset_split, audio_dir, audio_ext):\n",
    "        \"\"\"\n",
    "        Save alignment info as a dictionary of token mapped to a list of occurences with time stamps\n",
    "        Also, updates the count dictionary and list of tokens\n",
    "        \"\"\"\n",
    "        self.audio_dir = audio_dir\n",
    "        self.audio_ext = audio_ext\n",
    "        self.dataset_split = dataset_split\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        token_lst_dct = self.read_data()\n",
    "        self.get_token_alignment_ordered_lst(token_lst_dct, data_dir, dataset_split)\n",
    "        token_alignment_dct = self.get_token_alignment_dct(token_lst_dct)\n",
    "        for key, value in token_alignment_dct.items():\n",
    "            save_dct(\n",
    "                os.path.join(data_dir, f\"alignment_{key}_{dataset_split}.json\"), value\n",
    "            )\n",
    "\n",
    "        if \"train\" in dataset_split:\n",
    "            count_fn, token_lst_fn = {}, {}\n",
    "            for key in [\"phone\", \"word\"]:\n",
    "                count_fn[key] = os.path.join(data_dir, f\"{key}_count.json\")\n",
    "                token_lst_fn[key] = os.path.join(data_dir, f\"{key}.lst\")\n",
    "            self.update_tokens(count_fn, token_lst_fn, token_alignment_dct)\n",
    "\n",
    "    def read_data(self):\n",
    "        \"\"\"\n",
    "        Read data from textgrids into a list of tuples\n",
    "        \"\"\"\n",
    "        wrd_lst, phn_lst = [], []\n",
    "        parent_dir = os.path.join(self.data_dir, self.dataset_split)\n",
    "        all_fns = glob.glob(os.path.join(parent_dir, \"*/*/*.TextGrid\"))\n",
    "        for fname in tqdm(all_fns):\n",
    "            self.get_info(fname, phn_lst, wrd_lst)\n",
    "        token_lst_dct = {\"phone\": phn_lst, \"word\": wrd_lst}\n",
    "\n",
    "        return token_lst_dct\n",
    "\n",
    "    def get_token_alignment_dct(self, token_lst_dct):\n",
    "        \"\"\"\n",
    "        Convert a list of token-level alignments to a dictionary for a list of occurences of each token type\n",
    "        \"\"\"\n",
    "        token_alignment_dct = {}\n",
    "        for key, value in token_lst_dct.items():\n",
    "            token_alignment_dct[key] = {}\n",
    "            for item in tqdm(value):\n",
    "                utt_id, start, end, token = item.split(\" \")\n",
    "                audio_path = os.path.join(\n",
    "                    self.audio_dir,\n",
    "                    \"/\".join(utt_id.split(\"-\")[:2]),\n",
    "                    utt_id + \".\" + self.audio_ext,\n",
    "                )\n",
    "                _ = token_alignment_dct[key].setdefault(token, [])\n",
    "                token_alignment_dct[key][token].append((utt_id, audio_path, start, end))\n",
    "\n",
    "        return token_alignment_dct\n",
    "\n",
    "    def get_token_alignment_ordered_lst(self, token_lst_dct, data_dir, dataset_split):\n",
    "        \"\"\"\n",
    "        Save the list of token-level alignments to a tsv file\n",
    "        \"\"\"\n",
    "        for key, value in token_lst_dct.items():\n",
    "            write_str = []\n",
    "            for item in tqdm(value):\n",
    "                write_str.append(\"\\t\".join(item.split(\" \")))\n",
    "            write_fn = os.path.join(data_dir, f\"alignment_{key}_{dataset_split}.tsv\")\n",
    "            write_to_file(\"\\n\".join(write_str), write_fn)\n",
    "\n",
    "    def phn_map(self, phn_label):\n",
    "        if phn_label == \"sil\":\n",
    "            return \"SIL\"\n",
    "        elif phn_label[-1] in [\"0\", \"1\", \"2\"]:\n",
    "            return phn_label[:-1].lower()\n",
    "        else:\n",
    "            return phn_label.lower()\n",
    "\n",
    "    def txt_from_tier(self, tier_content, data_lst, fname, unit):\n",
    "        \"\"\"\n",
    "        Save as filename start end label\n",
    "        \"\"\"\n",
    "        for item in tier_content:\n",
    "            label = item.text\n",
    "            if label:  # check that it is non-empty\n",
    "                start = str(item.xmin)\n",
    "                end = str(item.xmax)\n",
    "                if \"phone\" in unit:  # map to the traditional 39 phone phn set\n",
    "                    label = self.phn_map(label)\n",
    "                text_out = \" \".join([fname, start, end, label])\n",
    "                if label not in [\"spn\", \"sp\"]:\n",
    "                    data_lst.append(text_out)\n",
    "\n",
    "    def get_info(self, fname, phn_lst, wrd_lst):\n",
    "        grid = textgrids.TextGrid(fname)\n",
    "        fname = fname.split(\"/\")[-1].split(\".\")[0]\n",
    "        self.txt_from_tier(grid[\"phones\"], phn_lst, fname, \"phone\")\n",
    "        self.txt_from_tier(grid[\"words\"], wrd_lst, fname, \"word\")\n",
    "\n",
    "    def update_tokens(self, count_fn, token_lst_fn, token_alignment_dct):\n",
    "        count_dct = {}\n",
    "        for token_type, value in count_fn.items():\n",
    "            if os.path.exists(value):\n",
    "                count_dct[token_type] = load_dct(value)\n",
    "            else:\n",
    "                count_dct[token_type] = {}\n",
    "            alignment_info_dct = token_alignment_dct[token_type]\n",
    "            for token, alignment_info_lst in alignment_info_dct.items():\n",
    "                _ = count_dct[token_type].setdefault(token, 0)\n",
    "                count_dct[token_type][token] += len(alignment_info_lst)\n",
    "\n",
    "            save_dct(value, count_dct[token_type])\n",
    "            dct = count_dct[token_type]\n",
    "            sorted_token_lst = sorted(dct, key=dct.get, reverse=True)\n",
    "            write_to_file(\"\\n\".join(sorted_token_lst), token_lst_fn[token_type])\n",
    "\n",
    "\n",
    "def combine_alignments(data_dir, data_split, token_type):\n",
    "    combined_dct = {}\n",
    "    if data_split == \"train-clean\":\n",
    "        constitutes = [\"train-clean-100\", \"train-clean-360\"]\n",
    "    elif data_split == \"train\":\n",
    "        constitutes = [\"train-clean-100\", \"train-clean-360\", \"train-other-500\"]\n",
    "    for sub_data_split in constitutes:\n",
    "        alignment_dct = load_dct(\n",
    "            os.path.join(data_dir, f\"alignment_{token_type}_{sub_data_split}.json\")\n",
    "        )\n",
    "        for token in tqdm(alignment_dct):\n",
    "            alignment_lst = alignment_dct[token]\n",
    "            _ = combined_dct.setdefault(token, [])\n",
    "            combined_dct[token].extend(alignment_lst)\n",
    "    \n",
    "    save_dct(\n",
    "        os.path.join(data_dir, f\"alignment_{token_type}_{data_split}.json\"),\n",
    "        combined_dct,\n",
    "    )\n",
    "\n",
    "\n",
    "def save_one_hot_encodings(token, data_dir, save_dir, num_tokens=-1):\n",
    "    token_lst = read_lst(os.path.join(data_dir, f\"{token}.lst\"))\n",
    "    if token == \"word\":\n",
    "        assert num_tokens != -1\n",
    "        token_lst.remove(\"<unk>\")\n",
    "        token_lst = token_lst[:num_tokens]\n",
    "    rep_mat = np.eye(len(token_lst))\n",
    "    rep_dct = {token: one_hot_arr for token, one_hot_arr in zip(token_lst, rep_mat)}\n",
    "    save_dct(os.path.join(save_dir, f\"{token}_embed.pkl\"), rep_dct)\n",
    "\n",
    "# combine_alignments()\n",
    "# save_one_hot_encodings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_data_samples\n",
    "def sample_utterances(data_dir, save_fn, audio_ext, dir_depth, num_samples):\n",
    "    \"\"\"\n",
    "    Save utterance ids and corresponding paths to the audio in a file\n",
    "    \"\"\"\n",
    "    search_path = \"/\".join([\"*\"] * dir_depth)\n",
    "    all_files = glob(os.path.join(data_dir, search_path + \".\" + audio_ext))\n",
    "    chosen_fnames = random.sample(all_files, num_samples)\n",
    "\n",
    "    chosen_sent_ids = [Path(fname).name.split(\".\")[0] for fname in chosen_fnames]\n",
    "    write_lst = [\n",
    "        \"\\t\".join([sent_id, fname])\n",
    "        for sent_id, fname in zip(chosen_sent_ids, chosen_fnames)\n",
    "    ]\n",
    "    write_to_file(\"\\n\".join(write_lst), save_fn)\n",
    "\n",
    "\n",
    "class tokenLevelSamples:\n",
    "    def __init__(\n",
    "        self, data_split, data_dir, data_sample, token, save_dir, dur_threshold=10000\n",
    "    ):\n",
    "        self.data_split = data_split\n",
    "        self.data_dir = data_dir\n",
    "        self.data_sample = data_sample\n",
    "        self.save_dir = save_dir\n",
    "        self.token = token\n",
    "        self.dur_threshold = dur_threshold  # seconds\n",
    "\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def sample_tokens(self, token_lst, min_cnt, max_cnt, alignment_dct):\n",
    "        \"\"\"\n",
    "        Sample alignments such that each token has a \"good\" representation\n",
    "        \"\"\"\n",
    "        sampled_alignments = {}\n",
    "        tot_dur = 0\n",
    "        for token in token_lst:\n",
    "            all_alignments = alignment_dct[token]\n",
    "            num_instances = len(all_alignments)\n",
    "            if \"train\" in self.data_split:\n",
    "                min_cnt = min([min_cnt, num_instances])\n",
    "                max_cnt = min([max_cnt, num_instances])\n",
    "                num_samples = random.randint(min_cnt, max_cnt)\n",
    "            else:\n",
    "                num_samples = min([num_instances, min_cnt])\n",
    "            chosen_alignments_idx = np.random.choice(\n",
    "                np.arange(0, num_instances), num_samples, replace=False\n",
    "            )\n",
    "            chosen_alignments = [all_alignments[idx] for idx in chosen_alignments_idx]\n",
    "            for sent_id, fname, start_time, end_time in chosen_alignments:\n",
    "                start_time, end_time = float(start_time), float(end_time)\n",
    "                _ = sampled_alignments.setdefault(sent_id, [])\n",
    "                sampled_alignments[sent_id].append((fname, start_time, end_time, token))\n",
    "                tot_dur += end_time - start_time\n",
    "        print(\"Total duration of %s spans: %.2f seconds\" % (self.token, tot_dur))\n",
    "        self.split_into_sublists(sampled_alignments)\n",
    "\n",
    "    def save_to_file(self, current_sample, alignment_dct):\n",
    "        print(\n",
    "            \"Saving %dth split of %s spans for %s sample %d\"\n",
    "            % (current_sample, self.token, self.data_split, self.data_sample)\n",
    "        )\n",
    "        save_dct(\n",
    "            os.path.join(\n",
    "                self.save_dir,\n",
    "                f\"{self.data_split}_segments_sample{self.data_sample}_{current_sample}.json\",\n",
    "            ),\n",
    "            alignment_dct,\n",
    "        )\n",
    "\n",
    "    def split_into_sublists(self, sampled_alignments):\n",
    "        \"\"\"\n",
    "        Split sampled alignments into sublists\n",
    "        \"\"\"\n",
    "        current_sample, current_dur = 0, 0\n",
    "        alignment_dct = {}\n",
    "\n",
    "        for sent_id, alignment_lst in sampled_alignments.items():\n",
    "            for fname, start_time, end_time, token in alignment_lst:\n",
    "                current_dur += end_time - start_time\n",
    "                if sent_id not in alignment_dct:\n",
    "                    alignment_dct[sent_id] = [fname]\n",
    "                alignment_dct[sent_id].append((start_time, end_time, token))\n",
    "                if current_dur > self.dur_threshold:\n",
    "                    self.save_to_file(current_sample, alignment_dct)\n",
    "                    current_sample += 1\n",
    "                    current_dur = 0\n",
    "                    alignment_dct = {}\n",
    "        if current_dur > 0:\n",
    "            self.save_to_file(current_sample, alignment_dct)\n",
    "\n",
    "    def sample_phone_alignments(self, num_phones=39):\n",
    "        \"\"\"\n",
    "        Sample phone alignments for MI experiments\n",
    "        \"\"\"\n",
    "        if \"train\" in self.data_split:\n",
    "            min_cnt, max_cnt = 3000, 7000\n",
    "        else:\n",
    "            min_cnt, max_cnt = 200, 1e6\n",
    "        phn_lst = read_lst(os.path.join(self.data_dir, \"phone.lst\"))\n",
    "        alignment_dct = load_dct(\n",
    "            os.path.join(self.data_dir, f\"alignment_phone_{self.data_split}.json\")\n",
    "        )\n",
    "        phn_lst.remove(\"SIL\")\n",
    "        assert len(phn_lst) == num_phones\n",
    "        self.sample_tokens(phn_lst, min_cnt, max_cnt, alignment_dct)\n",
    "\n",
    "    def sample_word_alignments(self, num_words=500):\n",
    "        \"\"\"\n",
    "        Sample word alignments for MI experiments\n",
    "        \"\"\"\n",
    "        # from nltk.corpus import stopwords\n",
    "        # english_stop_words = stopwords.words(\"english\")\n",
    "        if \"train\" in self.data_split:\n",
    "            if num_words == 350:\n",
    "                min_cnt = 800\n",
    "            elif num_words == 500:\n",
    "                min_cnt = 600\n",
    "            max_cnt = 1200\n",
    "        else:\n",
    "            min_cnt, max_cnt = 15, 1e6\n",
    "        alignment_dct = load_dct(\n",
    "            os.path.join(self.data_dir, f\"alignment_word_{self.data_split}.json\")\n",
    "        )\n",
    "        wrd_lst = read_lst(os.path.join(self.data_dir, \"word.lst\"))\n",
    "        wrd_lst.remove(\"<unk>\")\n",
    "        # wrd_lst = list(set(wrd_lst) - set(english_stop_words))[:num_words]\n",
    "        self.sample_tokens(wrd_lst[:num_words], min_cnt, max_cnt, alignment_dct)\n",
    "\n",
    "\n",
    "class AllWrdSegments:\n",
    "    def __init__(\n",
    "        self,\n",
    "        alignment_data_dir,\n",
    "        word_lst_pth,\n",
    "        save_dir,\n",
    "        dur_thresh=10000,\n",
    "        num_instances=200,\n",
    "    ):\n",
    "        self.data_dir = alignment_data_dir\n",
    "        self.dur_thresh = dur_thresh\n",
    "        self.max_cnt = num_instances\n",
    "        self.word_lst_pth = word_lst_pth\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def get_tot_dur(self, wrd_segment_lst):\n",
    "        start_times = np.array([float(item[2]) for item in wrd_segment_lst])\n",
    "        end_times = np.array([float(item[3]) for item in wrd_segment_lst])\n",
    "        tot_num_secs = np.sum(end_times - start_times)\n",
    "        return tot_num_secs\n",
    "\n",
    "    def find_valid_split_idx(self, split_to_dur, tot_segment_dur):\n",
    "        if tot_segment_dur > self.dur_thresh:\n",
    "            keys = [split_idx for split_idx, dur in split_to_dur.items() if dur == 0]\n",
    "        else:\n",
    "            keys = [\n",
    "                split_idx\n",
    "                for split_idx, dur in split_to_dur.items()\n",
    "                if (tot_segment_dur + dur) < self.dur_thresh\n",
    "            ]\n",
    "        if len(keys) == 0:\n",
    "            return len(split_to_dur)\n",
    "        else:\n",
    "            return keys[0]\n",
    "\n",
    "    def sample_word_segments(self):\n",
    "        alignment_dct = load_dct(\n",
    "            os.path.join(self.data_dir, f\"alignment_word_train.json\")\n",
    "        )\n",
    "        curr_split_idx = 0\n",
    "        split_to_segments = {0: []}\n",
    "        split_to_dur = {0: 0}\n",
    "        split_to_labels = {}\n",
    "        wrd_lst = read_lst(self.word_lst_pth)\n",
    "        for wrd in wrd_lst:\n",
    "            tot_num_wrd_segments = len(alignment_dct[wrd])\n",
    "            num_samples = np.min([self.max_cnt, tot_num_wrd_segments])\n",
    "            chosen_alignments_idx = np.random.choice(\n",
    "                np.arange(0, tot_num_wrd_segments), num_samples, replace=False\n",
    "            )\n",
    "            wrd_segments = [alignment_dct[wrd][idx] for idx in chosen_alignments_idx]\n",
    "            tot_segment_dur = self.get_tot_dur(wrd_segments)\n",
    "            split_idx = self.find_valid_split_idx(split_to_dur, tot_segment_dur)\n",
    "            _ = split_to_segments.setdefault(split_idx, [])\n",
    "            _ = split_to_dur.setdefault(split_idx, 0)\n",
    "            _ = split_to_labels.setdefault(split_idx, [])\n",
    "            split_to_dur[split_idx] += tot_segment_dur\n",
    "            split_to_segments[split_idx].extend(wrd_segments)\n",
    "            split_to_labels[split_idx].extend([wrd] * len(wrd_segments))\n",
    "        for split_idx, labels_lst in split_to_labels.items():\n",
    "            segment_lst = [\n",
    "                \",\".join(list(item)) for item in split_to_segments[split_idx]\n",
    "            ]\n",
    "            write_to_file(\n",
    "                \"\\n\".join(labels_lst),\n",
    "                os.path.join(self.save_dir, f\"labels_{split_idx}.lst\"),\n",
    "            )\n",
    "            write_to_file(\n",
    "                \"\\n\".join(segment_lst),\n",
    "                os.path.join(self.save_dir, f\"word_segments_{split_idx}.lst\"),\n",
    "            )\n",
    "\n",
    "\n",
    "def sample_segments(\n",
    "    token_type,\n",
    "    data_dir,\n",
    "    data_split,\n",
    "    num_tokens,\n",
    "    data_sample,\n",
    "    save_dir,\n",
    "    dur_threshold=10000,\n",
    "):\n",
    "    sample_obj = tokenLevelSamples(\n",
    "        data_split, data_dir, data_sample, token_type, save_dir, dur_threshold\n",
    "    )\n",
    "    getattr(sample_obj, f\"sample_{token_type}_alignments\")(num_tokens)\n",
    "\n",
    "\n",
    "def sample_all_word_instances(\n",
    "    alignment_data_dir, word_lst_pth, save_dir, dur_thresh=10000, num_instances=200\n",
    "):\n",
    "    \"\"\"\n",
    "    Sample word instances for processing word-by-word\n",
    "    \"\"\"\n",
    "    sample_obj = AllWrdSegments(\n",
    "        alignment_data_dir, word_lst_pth, save_dir, dur_thresh, num_instances\n",
    "    )\n",
    "    sample_obj.sample_word_segments()\n",
    "# 获取不同level的样本\n",
    "# sample_utterances\n",
    "# sample_segments\n",
    "# sample_all_word_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_rep.py\n",
    "#from model_utils import ModelLoader, FeatExtractor\n",
    "#from utils import read_lst, load_dct, write_to_file\n",
    "\n",
    "def save_rep(\n",
    "    model_name,\n",
    "    ckpt_pth,\n",
    "    save_dir,\n",
    "    utt_id_fn,\n",
    "    model_type=\"pretrained\",\n",
    "    rep_type=\"contextualized\",\n",
    "    dict_fn=None,\n",
    "    fbank_dir=None,\n",
    "    offset=False,\n",
    "    mean_pooling=False,\n",
    "    span=\"frame\",\n",
    "    pckg_dir=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract layer-wise representations from the model\n",
    "\n",
    "    ckpt_pth: path to the model checkpoint\n",
    "    save_dir: directory where the representations are saved\n",
    "    utt_id_fn: identifier for utterances\n",
    "    model_type: pretrained or finetuned\n",
    "    rep_type: contextualized or local or quantized\n",
    "    dict_fn: path to dictionary file in case of finetuned models\n",
    "    fbank_dir: directory that has filterbanks stored\n",
    "    offset: span representation attribute\n",
    "    mean_pooling: span representation attribute\n",
    "    span: frame | phone | word\n",
    "    \"\"\"\n",
    "    assert rep_type in [\"local\", \"quantized\", \"contextualized\"]\n",
    "\n",
    "    model_obj = ModelLoader(ckpt_pth, model_type, pckg_dir, dict_fn)\n",
    "    encoder, task_cfg = getattr(model_obj, model_name.split(\"_\")[0])()\n",
    "\n",
    "    Path(save_dir).mkdir(exist_ok=True, parents=True)\n",
    "    if \".tsv\" in utt_id_fn:\n",
    "        utt_id_lst = read_lst(utt_id_fn)\n",
    "        label_lst = None\n",
    "    else:\n",
    "        utt_id_dct = load_dct(utt_id_fn)\n",
    "        utt_id_lst = list(utt_id_dct.keys())\n",
    "        label_lst = []\n",
    "        label_lst_fn = os.path.join(\n",
    "            save_dir, \"..\", f'labels_{save_dir.split(\"/\")[-1]}.lst'\n",
    "        )\n",
    "    rep_dct = {}\n",
    "    write_flag = True\n",
    "    # local representations\n",
    "    transformed_fbank_lst, truncated_fbank_lst = [], []\n",
    "    # quantized representations\n",
    "    quantized_features, quantized_indices = [], []\n",
    "    quantized_features_dct, discrete_indices_dct = {}, {}\n",
    "\n",
    "    start = time.time()\n",
    "    for item in tqdm(utt_id_lst):\n",
    "        if span == \"frame\":\n",
    "            time_stamp_lst = None\n",
    "            utt_id, wav_fn = item.split(\"\\t\")\n",
    "        else:\n",
    "            utt_id = item\n",
    "            wav_fn = utt_id_dct[utt_id][0]\n",
    "            time_stamp_lst = utt_id_dct[utt_id][1:]\n",
    "        extract_obj = FeatExtractor(\n",
    "            encoder,\n",
    "            utt_id,\n",
    "            wav_fn,\n",
    "            rep_type,\n",
    "            model_name,\n",
    "            fbank_dir,\n",
    "            task_cfg,\n",
    "            offset=offset,\n",
    "            mean_pooling=mean_pooling,\n",
    "        )\n",
    "        getattr(extract_obj, model_name.split(\"_\")[0])()\n",
    "        if rep_type == \"local\":\n",
    "            extract_obj.extract_local_rep(\n",
    "                rep_dct, transformed_fbank_lst, truncated_fbank_lst\n",
    "            )\n",
    "\n",
    "        elif rep_type == \"contextualized\":\n",
    "            extract_obj.extract_contextualized_rep(rep_dct, time_stamp_lst, label_lst)\n",
    "\n",
    "        elif rep_type == \"quantized\":\n",
    "            extract_obj.extract_quantized_rep(\n",
    "                quantized_features,\n",
    "                quantized_indices,\n",
    "                quantized_features_dct,\n",
    "                discrete_indices_dct,\n",
    "            )\n",
    "\n",
    "    if span in [\"phone\", \"word\"]:\n",
    "        write_to_file(\"\\n\".join(label_lst), label_lst_fn)\n",
    "\n",
    "    if rep_type != \"quantized\":\n",
    "        extract_obj.save_rep_to_file(rep_dct, save_dir)\n",
    "\n",
    "    if rep_type == \"local\":\n",
    "        if \"avhubert\" not in model_name:\n",
    "            truncated_fbank_mat = np.concatenate(truncated_fbank_lst, 0)\n",
    "            np.save(os.path.join(fbank_dir, \"all_features.npy\"), truncated_fbank_mat)\n",
    "            sfx = \"\"\n",
    "        else:\n",
    "            sfx = \"_by4\"\n",
    "        transformed_fbank_mat = np.concatenate(transformed_fbank_lst, 0)\n",
    "        np.save(\n",
    "            os.path.join(fbank_dir, f\"all_features_downsampled{sfx}.npy\"),\n",
    "            transformed_fbank_mat,\n",
    "        )\n",
    "\n",
    "    elif rep_type == \"quantized\":\n",
    "        rep_mat = np.concatenate(quantized_features, 0)\n",
    "        idx_mat = np.concatenate(quantized_indices, 0)\n",
    "        np.save(os.path.join(save_dir, \"features.npy\"), rep_mat)\n",
    "        np.save(os.path.join(save_dir, \"indices.npy\"), idx_mat)\n",
    "        save_dct(\n",
    "            os.path.join(save_dir, \"quantized_features.pkl\"), quantized_features_dct\n",
    "        )\n",
    "        save_dct(os.path.join(save_dir, \"discrete_indices.pkl\"), discrete_indices_dct)\n",
    "        \n",
    "    print(\"%s representations saved to %s\" % (rep_type, save_dir))\n",
    "\n",
    "    print(\"Time required: %.1f mins\" % ((time.time() - start) / 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_scores\n",
    "class getCCA:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        fbank_dir,\n",
    "        rep_dir,\n",
    "        exp_name,\n",
    "        base_layer=0,\n",
    "        rep_dir2=None,\n",
    "        embed_dir=None,\n",
    "        sample_data_fn=None,\n",
    "        span=\"phone\",\n",
    "        mean_score=False,\n",
    "        eval_single_layer=False,\n",
    "        layer_num=-1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        exp_name: cca-mel | cca-intra | cca-inter | cca-glove | cca-agwe\n",
    "        \"\"\"\n",
    "        print(eval_single_layer)\n",
    "        if eval_single_layer:\n",
    "            assert layer_num != -1\n",
    "        self.layer_num = layer_num\n",
    "        self.eval_single_layer = eval_single_layer\n",
    "        self.num_conv_layers = LAYER_CNT[model_name][\"local\"]\n",
    "        self.num_transformer_layers = LAYER_CNT[model_name][\"contextualized\"]\n",
    "        self.fbank_dir = fbank_dir\n",
    "        self.rep_dir = rep_dir\n",
    "        self.base_layer = base_layer\n",
    "        self.rep_dir2 = rep_dir2\n",
    "        self.embed_fn = os.path.join(embed_dir, f'{exp_name.split(\"_\")[-1]}_embed.pkl')\n",
    "        self.sample_data_fn = sample_data_fn\n",
    "        self.model_name = model_name\n",
    "        self.score_dct = {}\n",
    "        if exp_name in [\"cca_glove\", \"cca_agwe\", \"cca_word\"]:\n",
    "            assert span == \"word\"\n",
    "        elif exp_name == \"cca_phone\":\n",
    "            assert span == \"phone\"\n",
    "        self.span = span\n",
    "        self.exp_name = exp_name\n",
    "        self.mean_score = mean_score\n",
    "\n",
    "    def get_score_flag(self, layer_id):\n",
    "        get_score = False\n",
    "        if self.eval_single_layer:\n",
    "            if self.layer_num == layer_id:\n",
    "                get_score = True\n",
    "        else:\n",
    "            get_score = True\n",
    "        return get_score\n",
    "\n",
    "    def get_cca_score(\n",
    "        self,\n",
    "        view1,\n",
    "        view2,\n",
    "        rep_dir,\n",
    "        layer_id,\n",
    "        label_lst=None,\n",
    "        force_train=False,\n",
    "        subset=None,\n",
    "    ):\n",
    "        start_time = time.time()\n",
    "        sim_score = tools.get_cca_score(\n",
    "            view1,\n",
    "            view2,\n",
    "            rep_dir,\n",
    "            layer_id,\n",
    "            self.exp_name,\n",
    "            label_lst=label_lst,\n",
    "            subset=subset,\n",
    "            force_train=force_train,\n",
    "            mean_score=self.mean_score,\n",
    "        )\n",
    "        self.score_dct[layer_id] = sim_score\n",
    "\n",
    "        print_score = np.round(sim_score, 2)\n",
    "        if isinstance(layer_id, int):\n",
    "            layer_type = \"Transformer\"\n",
    "            layer_num = layer_id\n",
    "        elif \"C\" in layer_id:\n",
    "            layer_type = \"Conv\"\n",
    "            layer_num = layer_id[1:]\n",
    "        elif \"T\" in layer_id:\n",
    "            layer_type = \"Transformer\"\n",
    "            layer_num = layer_id[1:]\n",
    "        print(\n",
    "            f\"[{format_time(start_time)}] {layer_type} layer {layer_num}: {print_score}\"\n",
    "        )\n",
    "        return sim_score\n",
    "\n",
    "    def cca_mel(self):\n",
    "        rep_dir_contextualized = os.path.join(\n",
    "            self.rep_dir, \"contextualized\", \"frame_level\"\n",
    "        )\n",
    "        rep_dir_local = os.path.join(self.rep_dir, \"local\", \"frame_level\")\n",
    "        all_fbank = np.load(os.path.join(self.fbank_dir, \"all_features.npy\"))\n",
    "\n",
    "        if \"avhubert\" in self.model_name:\n",
    "            all_fbank_downsampled = np.load(\n",
    "                os.path.join(self.fbank_dir, \"all_features_downsampled_by4.npy\")\n",
    "            )\n",
    "        else:\n",
    "            all_fbank_downsampled = np.load(\n",
    "                os.path.join(self.fbank_dir, \"all_features_downsampled.npy\")\n",
    "            )\n",
    "        layer_start = 1\n",
    "\n",
    "        for layer_id in range(1, self.num_conv_layers + 1):\n",
    "            if self.get_score_flag(f\"C{layer_id}\"):\n",
    "                start_time = time.time()\n",
    "                fname = \"layer_\" + str(layer_id) + \".npy\"\n",
    "                rep_mat = np.load(os.path.join(rep_dir_local, fname))\n",
    "                if layer_id != self.num_conv_layers:  # downsample model representations\n",
    "                    view1 = all_fbank.T\n",
    "                    subset = \"downsampled\"\n",
    "                else:\n",
    "                    view1 = all_fbank_downsampled.T\n",
    "                    subset = \"original\"\n",
    "                sim_score = self.get_cca_score(\n",
    "                    view1,\n",
    "                    rep_mat.T,\n",
    "                    rep_dir_local,\n",
    "                    f\"C{layer_id}\",\n",
    "                    subset=subset,\n",
    "                )\n",
    "\n",
    "        for layer_id in range(layer_start, self.num_transformer_layers + 1):\n",
    "            if self.get_score_flag(f\"T{layer_id}\"):\n",
    "                start_time = time.time()\n",
    "                fname = \"layer_\" + str(layer_id) + \".npy\"\n",
    "                rep_mat = np.load(os.path.join(rep_dir_contextualized, fname))\n",
    "                sim_score = self.get_cca_score(\n",
    "                    all_fbank_downsampled.T,\n",
    "                    rep_mat.T,\n",
    "                    rep_dir_contextualized,\n",
    "                    f\"T{layer_id}\",\n",
    "                )\n",
    "\n",
    "    def cca_intra(self):\n",
    "        rep_dir = os.path.join(self.rep_dir, \"contextualized\", \"frame_level\")\n",
    "        z_mat = np.load(os.path.join(rep_dir, f\"layer_{self.base_layer}.npy\"))\n",
    "        for layer_id in range(1, self.num_transformer_layers + 1):\n",
    "            if self.get_score_flag(layer_id):\n",
    "                start_time = time.time()\n",
    "                c_mat = np.load(os.path.join(rep_dir, f\"layer_{layer_id}.npy\"))\n",
    "                sim_score = self.get_cca_score(\n",
    "                    z_mat.T,\n",
    "                    c_mat.T,\n",
    "                    rep_dir,\n",
    "                    layer_id,\n",
    "                )\n",
    "\n",
    "    def cca_inter(self):\n",
    "        rep_dir1 = os.path.join(self.rep_dir, \"contextualized\", \"frame_level\")\n",
    "        rep_dir2 = os.path.join(self.rep_dir2, \"contextualized\", \"frame_level\")\n",
    "        for layer_id in range(1, self.num_transformer_layers + 1):\n",
    "            if self.get_score_flag(layer_id):\n",
    "                start_time = time.time()\n",
    "                c_mat1 = np.load(os.path.join(rep_dir1, f\"layer_{layer_id}.npy\"))\n",
    "                c_mat2 = np.load(os.path.join(rep_dir2, f\"layer_{layer_id}.npy\"))\n",
    "                sim_score = self.get_cca_score(\n",
    "                    c_mat1.T,\n",
    "                    c_mat2.T,\n",
    "                    rep_dir1,\n",
    "                    layer_id,\n",
    "                    rep_dir2=rep_dir2,\n",
    "                )\n",
    "\n",
    "    def get_num_splits(self):\n",
    "        search_str = self.sample_data_fn.replace(\"_0.json\", \"_*.json\")\n",
    "        num_splits = len(glob(search_str))\n",
    "        assert num_splits != 0, \"data not found\"\n",
    "        return num_splits\n",
    "\n",
    "    def update_label_lst(self, split_num, all_labels, dir_name=None):\n",
    "        assert dir_name is not None\n",
    "        fname = os.path.join(dir_name, f\"labels_{split_num}.lst\")\n",
    "        label_lst = read_lst(fname)\n",
    "        all_labels.extend(label_lst)\n",
    "\n",
    "    def filter_label_lst(self, all_labels, embed_dct):\n",
    "        num_labels = len(all_labels)\n",
    "        valid_indices = list(np.arange(num_labels))\n",
    "        valid_label_lst = []\n",
    "        for idx, label in enumerate(all_labels):\n",
    "            if label not in embed_dct:\n",
    "                valid_indices.remove(idx)\n",
    "        print(\n",
    "            f\"{num_labels-len(valid_indices)} of {num_labels} {self.span} segments dropped\"\n",
    "        )\n",
    "        return valid_indices\n",
    "\n",
    "    def cca_embed(self):\n",
    "        rep_dir = os.path.join(self.rep_dir, \"contextualized\", f\"{self.span}_level\")\n",
    "        embed_dct = load_dct(self.embed_fn)\n",
    "        num_splits = self.get_num_splits()\n",
    "        all_labels = []\n",
    "        for layer_id in range(self.num_transformer_layers + 1):\n",
    "            if self.get_score_flag(layer_id):\n",
    "                start_time = time.time()\n",
    "                all_rep = []\n",
    "                for split_num in range(num_splits):\n",
    "                    rep_fn = os.path.join(rep_dir, str(split_num), f\"layer_{layer_id}.npy\")\n",
    "                    rep_mat = np.load(rep_fn)\n",
    "                    all_rep.extend(rep_mat)\n",
    "                    if layer_id == 0 or self.eval_single_layer:\n",
    "                        self.update_label_lst(split_num, all_labels, rep_dir)\n",
    "\n",
    "                all_rep = np.array(all_rep)  # N x d\n",
    "                if layer_id == 0 or self.eval_single_layer:\n",
    "                    valid_indices = self.filter_label_lst(all_labels, embed_dct)\n",
    "                    all_embed = np.array(\n",
    "                        [embed_dct[all_labels[idx1]] for idx1 in valid_indices]\n",
    "                    )\n",
    "                    valid_label_lst = [all_labels[idx1] for idx1 in valid_indices]\n",
    "                all_rep = all_rep[np.array(valid_indices)]\n",
    "                sim_score = self.get_cca_score(\n",
    "                    all_rep.T,\n",
    "                    all_embed.T,\n",
    "                    rep_dir,\n",
    "                    layer_id,\n",
    "                    label_lst=valid_label_lst,\n",
    "                )\n",
    "\n",
    "    def cca_word(self):\n",
    "        self.cca_embed()\n",
    "\n",
    "    def cca_phone(self):\n",
    "        self.cca_embed()\n",
    "\n",
    "    def cca_glove(self):\n",
    "        self.cca_embed()\n",
    "\n",
    "    def cca_agwe(self):\n",
    "        self.cca_embed()\n",
    "\n",
    "\n",
    "class getMI:\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_dataset_split,\n",
    "        sample_data_dir,\n",
    "        rep_dir,\n",
    "        save_fn,\n",
    "        layer_id,\n",
    "        span,\n",
    "        iter_num,\n",
    "        data_sample,\n",
    "        num_clusters,\n",
    "        train_dataset_split=None,\n",
    "    ):\n",
    "        self.sample_data_dir = sample_data_dir\n",
    "        self.rep_dir = rep_dir\n",
    "        self.save_fn = save_fn\n",
    "        self.layer_id = layer_id\n",
    "        self.data_sample = data_sample\n",
    "        self.iter_num = iter_num\n",
    "\n",
    "        if \"train\" in eval_dataset_split:\n",
    "            self.all_rep, self.all_labels = self.read_data(\n",
    "                eval_dataset_split\n",
    "            )  # load train data\n",
    "            self.eval_rep, self.eval_labels = None, None\n",
    "        elif \"dev\" in eval_dataset_split:\n",
    "            self.all_rep, self.all_labels = self.read_data(\n",
    "                train_dataset_split\n",
    "            )  # load train data\n",
    "            self.eval_rep, self.eval_labels = self.read_data(eval_dataset_split)\n",
    "\n",
    "        max_iter = 500\n",
    "        if span == \"phone\":\n",
    "            # n_clusters = 500\n",
    "            n_clusters = num_clusters\n",
    "            batch_size = 1500\n",
    "        elif span == \"word\":\n",
    "            # n_clusters = 5000\n",
    "            n_clusters = num_clusters\n",
    "            batch_size = 4000\n",
    "        self.mi_score = tools.get_mi_score(\n",
    "            n_clusters,\n",
    "            batch_size,\n",
    "            max_iter,\n",
    "            eval_dataset_split,\n",
    "            self.all_rep,\n",
    "            self.all_labels,\n",
    "            self.eval_rep,\n",
    "            self.eval_labels,\n",
    "        )\n",
    "\n",
    "    def write_to_file(self, mi_score):\n",
    "        \"\"\"\n",
    "        Saving scores to a file\n",
    "        \"\"\"\n",
    "        with open(self.save_fn, \"a\") as f:\n",
    "            f.write(\n",
    "                \",\".join(\n",
    "                    list(\n",
    "                        map(\n",
    "                            str,\n",
    "                            [\n",
    "                                self.layer_id,\n",
    "                                self.data_sample,\n",
    "                                self.iter_num,\n",
    "                                np.round(mi_score, 3),\n",
    "                            ],\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                + \"\\n\"\n",
    "            )\n",
    "\n",
    "    def read_data(self, split):\n",
    "        rep_dir = self.rep_dir.replace(\"dev-clean\", split)\n",
    "        sample_data_fn = os.path.join(\n",
    "            self.sample_data_dir, f\"{split}_segments_sample{self.data_sample}_0.json\"\n",
    "        )\n",
    "        search_str = sample_data_fn.replace(\"_0.json\", \"_*.json\")\n",
    "        num_splits = len(glob(search_str))\n",
    "        assert num_splits != 0\n",
    "        all_rep, all_labels = [], []\n",
    "        for idx in range(num_splits):\n",
    "            rep_fn = os.path.join(rep_dir, str(idx), f\"layer_{self.layer_id}.npy\")\n",
    "            rep_mat = np.load(rep_fn)\n",
    "            all_rep.extend(rep_mat)\n",
    "            label_lst = read_lst(os.path.join(rep_dir, f\"labels_{idx}.lst\"))\n",
    "            all_labels.extend(label_lst)\n",
    "\n",
    "        all_rep = np.array(all_rep)\n",
    "        assert len(all_rep) == len(all_labels)\n",
    "        return all_rep, all_labels\n",
    "\n",
    "\n",
    "def evaluate_mi(\n",
    "    eval_dataset_split,\n",
    "    sample_data_dir,\n",
    "    rep_dir,\n",
    "    save_fn,\n",
    "    layer_id,\n",
    "    span,\n",
    "    iter_num,\n",
    "    data_sample,\n",
    "    num_clusters,\n",
    "    train_dataset_split=None,\n",
    "):\n",
    "    mi_obj = getMI(\n",
    "        eval_dataset_split,\n",
    "        sample_data_dir,\n",
    "        rep_dir,\n",
    "        save_fn,\n",
    "        layer_id,\n",
    "        span,\n",
    "        iter_num,\n",
    "        data_sample,\n",
    "        num_clusters,\n",
    "        train_dataset_split,\n",
    "    )\n",
    "    mi_obj.write_to_file(mi_obj.mi_score)\n",
    "\n",
    "\n",
    "def evaluate_cca(\n",
    "    model_name,\n",
    "    save_fn,\n",
    "    fbank_dir,\n",
    "    rep_dir,\n",
    "    exp_name,\n",
    "    base_layer=0,\n",
    "    rep_dir2=None,\n",
    "    embed_dir=None,\n",
    "    sample_data_fn=None,\n",
    "    span=\"phone\",\n",
    "    mean_score=False,\n",
    "    eval_single_layer=False,\n",
    "    layer_num=-1,\n",
    "):\n",
    "    cca_obj = getCCA(\n",
    "        model_name,\n",
    "        fbank_dir,\n",
    "        rep_dir,\n",
    "        exp_name,\n",
    "        base_layer,\n",
    "        rep_dir2,\n",
    "        embed_dir,\n",
    "        sample_data_fn,\n",
    "        span,\n",
    "        mean_score,\n",
    "        eval_single_layer,\n",
    "        layer_num\n",
    "    )\n",
    "    getattr(cca_obj, exp_name)()\n",
    "\n",
    "    if mean_score:\n",
    "        save_fn = save_fn.replace(\".json\", \"_mean.json\")\n",
    "    \n",
    "    if eval_single_layer:\n",
    "        assert len(cca_obj.score_dct) == 1\n",
    "        sample_num = save_fn.split(\"_\")[-1].split(\".\")[0][-1]\n",
    "        save_fn = \"_\".join(save_fn.split(\"_\")[:-1]) + \".lst\"\n",
    "        add_to_file(\n",
    "            \",\".join(\n",
    "                list(map(str, [layer_num, sample_num, cca_obj.score_dct[layer_num]]))\n",
    "            )\n",
    "            + \"\\n\",\n",
    "            save_fn,\n",
    "        )\n",
    "    else:\n",
    "        save_dct(save_fn, cca_obj.score_dct)\n",
    "    print(f\"Result saved at {save_fn}\")\n",
    "\n",
    "def evaluate_wordsim(model_name, wordsim_task_fn, embedding_dir, save_fn):\n",
    "    wordsim_tasks = load_dct(wordsim_task_fn)\n",
    "    num_transformer_layers = LAYER_CNT[model_name][\"contextualized\"]\n",
    "    res_dct = {}\n",
    "    _ = res_dct.setdefault(\"micro average\", {})\n",
    "    _ = res_dct.setdefault(\"macro average\", {})\n",
    "    mean_score = 0\n",
    "    for layer_num in range(num_transformer_layers + 1):\n",
    "        embed_dct = load_dct(os.path.join(embedding_dir, f\"layer{layer_num}.json\"))\n",
    "        res_dct[\"micro average\"][layer_num] = 0\n",
    "        res_dct[\"macro average\"][layer_num] = 0\n",
    "        num_pairs = 0\n",
    "        for task_name, task_lst in wordsim_tasks.items():\n",
    "            srho_score = tools.get_similarity_score(task_lst, embed_dct)\n",
    "            res_dct[\"micro average\"][layer_num] += srho_score * len(task_lst)\n",
    "            res_dct[\"macro average\"][layer_num] += srho_score\n",
    "            num_pairs += len(task_lst)\n",
    "            _ = res_dct.setdefault(task_name, {})\n",
    "            res_dct[task_name][layer_num] = srho_score\n",
    "        res_dct[\"micro average\"][layer_num] /= num_pairs\n",
    "        res_dct[\"macro average\"][layer_num] /= len(wordsim_tasks)\n",
    "    save_dct(save_fn, res_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('speech')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03c8b8d2efeff34910646f2825e7ebf40fce6c0407b50a5bcb8520ed0a04a344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
